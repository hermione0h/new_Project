{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "from scipy.io import savemat \n",
    "import os\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(root):\n",
    "    dataset = []\n",
    "    with open(root) as f:\n",
    "        #print(root)\n",
    "        content = f.read().splitlines()\n",
    "    for line in content:\n",
    "        #path = np.load(line)\n",
    "        dataset.append(line)\n",
    "    return dataset\n",
    "class lateSpeech(data.Dataset):\n",
    "    def __init__(self,root1,root2):\n",
    "        self.data1 = make_dataset(root1)\n",
    "        #print(self.data1[0])\n",
    "        self.data2 = make_dataset(root2)\n",
    "\n",
    "        self.root1 = root1\n",
    "        self.root2 = root2\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        Xfile1 = self.data1[index]\n",
    "\n",
    "        de_file = self.data2[index]\n",
    "        X1 = np.load(Xfile1)\n",
    "        X1 = normalize(X1)\n",
    "        de = np.load(de_file)\n",
    "        \n",
    "\n",
    "        return torch.from_numpy(X1).t().float(),torch.from_numpy(de).float() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputSize(x):\n",
    "    a = np.load(x)\n",
    "    b = a.shape\n",
    "    return b[0]\n",
    "def seqLen(x):\n",
    "    a = np.load(x)\n",
    "    b = a.shape\n",
    "    return b[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5300 758\n"
     ]
    }
   ],
   "source": [
    "input_file = '/data/liyuy/PROJECTS/DEREVERB3/timit_8k/reverb_train/train_wlen_80_nfft_128_overlap_10/reverb_rir5000_roomNum10_t600.9_loc500_8kHz.npy'\n",
    "new_file = '/data/liyuy/PROJECTS/DEREVERB3/timit_8k/reverb_valid/valid_wlen_80_nfft_128_overlap_10/reverb_rir0500_roomNum10_t600.9_loc500_8kHz.npy'\n",
    "print(seqLen(new_file),seqLen(input_file))\n",
    "\n",
    "class param:\n",
    "    #img_size = (80, 80)\n",
    "    bs = 20\n",
    "    lr = 10e-4\n",
    "    epochs = 100\n",
    "    hsize = 513\n",
    "    hlayer = 6\n",
    "    osize = 1026\n",
    "    lstm_s = InputSize(input_file)\n",
    "    lstm_l = seqLen(input_file)\n",
    "#print(param.lstm_inputsize)\n",
    "\n",
    "mix1_train = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/train/train_wlen_80_nfft_128_overlap_10.txt\"\n",
    "\n",
    "de_train = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/target_address/train/train_target.txt\"\n",
    "\n",
    "mix1_val = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/valid/valid_wlen_80_nfft_128_overlap_10.txt\"\n",
    "\n",
    "de_val = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/target_address/valid/valid_target.txt\"\n",
    "\n",
    "#mix1_test = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/test/test1/test_wlen_80_nfft_128_overlap_10.txt\"\"\n",
    "\n",
    "#de_test = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/address_seg/target/testing/complex/multi/reverb_900_1_0.9.txt\"\n",
    "\n",
    "\n",
    "train_dl = data.DataLoader(lateSpeech(mix1_train,de_train),\n",
    "                        batch_size=param.bs,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=torch.cuda.is_available())\n",
    "val_dl = data.DataLoader(lateSpeech(mix1_val,de_val),\n",
    "                    batch_size=param.bs,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "#test_dl = data.DataLoader(lateSpeech(mix1_test,de_test),\n",
    "#                         batch_size=param.bs,\n",
    "#                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_hn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_hn,self).__init__()\n",
    "        self.hsize = param.hsize\n",
    "        self.hlayer = param.hlayer\n",
    "        self.batchSize = param.bs\n",
    "        self.h0 = self.init_hidden(self.hsize,self.hlayer)\n",
    "        self.c0 = self.init_cell(self.hsize,self.hlayer)\n",
    "        self.lstm = nn.LSTM(param.lstm_s,self.hsize,self.hlayer,batch_first=True) \n",
    "        self.fc1 = nn.Linear(param.lstm_l*self.hsize,self.hsize)\n",
    "        self.fc2 = nn.Linear(self.hsize,param.osize)\n",
    "    def init_hidden(self,hidden_size,hidden_layer):\n",
    "        return Variable(torch.zeros(hidden_layer,self.batchSize, hidden_size).cuda())\n",
    "    \n",
    "    def init_cell(self,hidden_size,hidden_layer):\n",
    "        return Variable(torch.zeros(hidden_layer,self.batchSize, hidden_size).cuda())   \n",
    "        \n",
    "    def forward(self,sig1):\n",
    "        \n",
    "        hx = self.h0\n",
    "        cx = self.c0\n",
    "        \n",
    "        out,(hx,cx) = self.lstm(sig1,(hx,cx))\n",
    "        \n",
    "        new_out = out.contiguous().view(-1,param.lstm_l * self.hsize)\n",
    "        \n",
    "        output1 = Func.relu(self.fc1(new_out))\n",
    "        \n",
    "        de_out = torch.tanh(self.fc2(output1))\n",
    "        \n",
    "        \n",
    "        return de_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_hn().cuda()\n",
    "def weights(m):\n",
    "    if isinstance(m,nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data,0.1)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            else:\n",
    "                nn.init.normal_(param.data) \n",
    "model.apply(weights)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=param.lr)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dl, model):\n",
    "    loss = 0\n",
    "    for X1, y1 in dl:\n",
    "        X1, y1 = Variable(X1).cuda(), Variable(y1).cuda()\n",
    "        output = model(X1)\n",
    "    \n",
    "        loss1 = criterion(output,y1)\n",
    "\n",
    "        \n",
    "        loss += loss1.cpu().item() * param.bs\n",
    "    loss = loss / (len(val_dl.dataset))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 388854]' is invalid for input of size 54378000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-b5af18ab0cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'before'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'after'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m#file2.write('{:1.9f}'.format(val_loss)+\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-8abc3b9054be>\u001b[0m in \u001b[0;36mget_loss\u001b[0;34m(dl, model)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-aa7f768d2e07>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sig1)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mnew_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_l\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 388854]' is invalid for input of size 54378000"
     ]
    }
   ],
   "source": [
    "iters = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "it = 0\n",
    "min_loss = np.inf\n",
    "bst_model_fpath = '/data/liyuy/PROJECTS/DEREVERB3/LSTM/exp5/model/bst_model_wlen_80_nfft_128_overlap_10.pth'\n",
    "model.train(True)\n",
    "\n",
    "for epoch in range(1,param.epochs):\n",
    "    loss = 0.0\n",
    "    model.train(True)\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for mag1,de_gtruth in train_dl:\n",
    "            #print(mag.shape)\n",
    "            mag1 = Variable(mag1.cuda())  # [N, 1, H, W]\n",
    "            de_gtruth = Variable(de_gtruth.cuda())\n",
    "\n",
    "            output = model(mag1)# [N, 2, H, W]\n",
    "            \n",
    "            \n",
    "\n",
    "            pLoss = criterion(output,de_gtruth)\n",
    "\n",
    "            loss += pLoss.cpu().item() * param.bs\n",
    "            optim.zero_grad()\n",
    "            pLoss.backward()\n",
    "            optim.step()\n",
    "        avgLoss = loss/len(train_dl.dataset)\n",
    "    #file1.write('{:1.9f}'.format(avgLoss)+\"\\n\")    \n",
    "    model.eval()\n",
    "    print('before')\n",
    "    val_loss = get_loss(val_dl, model)\n",
    "    print('after')\n",
    "    #file2.write('{:1.9f}'.format(val_loss)+\"\\n\")     \n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), bst_model_fpath)              \n",
    "        print('Epoch {:2}, Train Loss:{:>.9f}, Validation Loss:{:>.9f}'.format(epoch,avgLoss,min_loss))\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
