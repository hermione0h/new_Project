{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as Func\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "from scipy.io import savemat \n",
    "import os\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(root):\n",
    "    dataset = []\n",
    "    with open(root) as f:\n",
    "        #print(root)\n",
    "        content = f.read().splitlines()\n",
    "    for line in content:\n",
    "        #path = np.load(line)\n",
    "        dataset.append(line)\n",
    "    return dataset\n",
    "class lateSpeech(data.Dataset):\n",
    "    def __init__(self,root1,root2):\n",
    "        self.data1 = make_dataset(root1)\n",
    "        #print(self.data1[0])\n",
    "        self.data2 = make_dataset(root2)\n",
    "\n",
    "        self.root1 = root1\n",
    "        self.root2 = root2\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        Xfile1 = self.data1[index]\n",
    "\n",
    "        de_file = self.data2[index]\n",
    "        X1 = np.load(Xfile1)\n",
    "        X1 = normalize(X1)\n",
    "        de = np.load(de_file)\n",
    "        \n",
    "\n",
    "        return torch.from_numpy(X1).t().float(),torch.from_numpy(de).float() \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InputSize(x):\n",
    "    a = np.load(x)\n",
    "    b = a.shape\n",
    "    return b[0]\n",
    "def seqLen(x):\n",
    "    a = np.load(x)\n",
    "    b = a.shape\n",
    "    return b[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "758 758\n"
     ]
    }
   ],
   "source": [
    "input_file = '/data/liyuy/PROJECTS/DEREVERB3/timit_8k/reverb_train/train_wlen_80_nfft_128_overlap_10/reverb_rir5000_roomNum10_t600.9_loc500_8kHz.npy'\n",
    "new_file = '/data/liyuy/PROJECTS/DEREVERB3/timit_8k/reverb_valid/valid_wlen_80_nfft_128_overlap_10/reverb_rir0500_roomNum10_t600.9_loc500_8kHz.npy'\n",
    "print(seqLen(new_file),seqLen(input_file))\n",
    "\n",
    "class param:\n",
    "    #img_size = (80, 80)\n",
    "    bs = 20\n",
    "    lr = 10e-4\n",
    "    epochs = 100\n",
    "    hsize = 513\n",
    "    hlayer = 6\n",
    "    osize = 1026\n",
    "    lstm_s = InputSize(input_file)\n",
    "    lstm_l = seqLen(input_file)\n",
    "    ts = 1\n",
    "\n",
    "mix1_train = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/train/train_wlen_80_nfft_128_overlap_10.txt\"\n",
    "\n",
    "de_train = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/target_address/train/train_target.txt\"\n",
    "\n",
    "mix1_val = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/valid/valid_wlen_80_nfft_128_overlap_10.txt\"\n",
    "\n",
    "de_val = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/target_address/valid/valid_target.txt\"\n",
    "\n",
    "#mix1_test = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/stft_address/test/test1/test_wlen_80_nfft_128_overlap_10.txt\"\"\n",
    "\n",
    "#de_test = \"/data/liyuy/PROJECTS/DEREVERB3/block_conv/address_seg/target/testing/complex/multi/reverb_900_1_0.9.txt\"\n",
    "\n",
    "\n",
    "train_dl = data.DataLoader(lateSpeech(mix1_train,de_train),\n",
    "                        batch_size=param.bs,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=torch.cuda.is_available())\n",
    "val_dl = data.DataLoader(lateSpeech(mix1_val,de_val),\n",
    "                    batch_size=param.bs,\n",
    "                    shuffle=False,\n",
    "                    pin_memory=torch.cuda.is_available())\n",
    "\n",
    "#test_dl = data.DataLoader(lateSpeech(mix1_test,de_test),\n",
    "#                         batch_size=param.bs,\n",
    "#                         shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_hn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM_hn,self).__init__()\n",
    "        self.hsize = param.hsize\n",
    "        self.hlayer = param.hlayer\n",
    "        self.batchSize = param.bs\n",
    "        self.h0 = self.init_hidden(self.hsize,self.hlayer)\n",
    "        self.c0 = self.init_cell(self.hsize,self.hlayer)\n",
    "        self.lstm = nn.LSTM(param.lstm_s,self.hsize,self.hlayer,batch_first=True) \n",
    "        self.fc1 = nn.Linear(param.lstm_l*self.hsize,self.hsize)\n",
    "        self.fc2 = nn.Linear(self.hsize,param.osize)\n",
    "    def init_hidden(self,hidden_size,hidden_layer):\n",
    "        return Variable(torch.zeros(hidden_layer,self.batchSize, hidden_size).cuda())\n",
    "    \n",
    "    def init_cell(self,hidden_size,hidden_layer):\n",
    "        return Variable(torch.zeros(hidden_layer,self.batchSize, hidden_size).cuda())   \n",
    "        \n",
    "    def forward(self,sig1):\n",
    "        \n",
    "        hx = self.h0\n",
    "        cx = self.c0\n",
    "        \n",
    "        out,(hx,cx) = self.lstm(sig1,(hx,cx))\n",
    "        \n",
    "        new_out = out.contiguous().view(-1,param.lstm_l * self.hsize)\n",
    "        \n",
    "        output1 = Func.relu(self.fc1(new_out))\n",
    "        \n",
    "        de_out = Func.leaky_relu(self.fc2(output1))\n",
    "        \n",
    "        \n",
    "        return de_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_hn().cuda()\n",
    "def weights(m):\n",
    "    if isinstance(m,nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        nn.init.constant_(m.bias.data,0.1)\n",
    "    elif isinstance(m, nn.LSTM):\n",
    "        for param in m.parameters():\n",
    "            if len(param.shape) >= 2:\n",
    "                nn.init.orthogonal_(param.data)\n",
    "            else:\n",
    "                nn.init.normal_(param.data) \n",
    "model.apply(weights)\n",
    "optim = torch.optim.Adam(model.parameters(), lr=param.lr)\n",
    "\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loss(dl, model):\n",
    "    loss = 0\n",
    "    for X1, y1 in dl:\n",
    "        X1, y1 = Variable(X1).cuda(), Variable(y1).cuda()\n",
    "        output = model(X1)\n",
    "    \n",
    "        loss1 = criterion(output,y1)\n",
    "\n",
    "        \n",
    "        loss += loss1.cpu().item() * param.bs\n",
    "    loss = loss / (len(val_dl.dataset))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Train Loss:0.356883924, Validation Loss:0.003124676\n",
      "1\n",
      "Epoch  2, Train Loss:0.002765336, Validation Loss:0.002662965\n",
      "2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-41bb1a35a865>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0mde_gtruth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_gtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmag1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# [N, 2, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-d688681057a1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sig1)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mcx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnew_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_l\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 559\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_tensor\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0munsorted_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_batch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munsorted_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward_impl\u001b[0;34m(self, input, hx, batch_sizes, max_batch_size, sorted_indices)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m             result = _VF.lstm(input, hx, self._get_flat_weights(), self.bias, self.num_layers,\n\u001b[0;32m--> 522\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    523\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._get_flat_weights(), self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iters = []\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "it = 0\n",
    "min_loss = np.inf\n",
    "bst_model_fpath = '/data/liyuy/PROJECTS/DEREVERB3/LSTM/exp5/model/bst_model_wlen_80_nfft_128_overlap_10.pth'\n",
    "model.train(True)\n",
    "\n",
    "for epoch in range(1,param.epochs):\n",
    "    loss = 0.0\n",
    "    model.train(True)\n",
    "    with torch.set_grad_enabled(True):\n",
    "        for mag1,de_gtruth in train_dl:\n",
    "            #print(mag.shape)\n",
    "            mag1 = Variable(mag1.cuda())  # [N, 1, H, W]\n",
    "            de_gtruth = Variable(de_gtruth.cuda())\n",
    "\n",
    "            output = model(mag1)# [N, 2, H, W]\n",
    "            \n",
    "            \n",
    "\n",
    "            pLoss = criterion(output,de_gtruth)\n",
    "\n",
    "            loss += pLoss.cpu().item() * param.bs\n",
    "            optim.zero_grad()\n",
    "            pLoss.backward()\n",
    "            optim.step()\n",
    "        avgLoss = loss/len(train_dl.dataset)\n",
    "      \n",
    "    model.eval()\n",
    "    \n",
    "    val_loss = get_loss(val_dl, model)\n",
    "    \n",
    "     \n",
    "    if val_loss < min_loss:\n",
    "        min_loss = val_loss\n",
    "        torch.save(model.state_dict(), bst_model_fpath)              \n",
    "        print('Epoch {:2}, Train Loss:{:>.9f}, Validation Loss:{:>.9f}'.format(epoch,avgLoss,min_loss))\n",
    "    print(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_model_fpath = '/data/liyuy/PROJECTS/DEREVERB3/LSTM/exp5/model/bst_model_wlen_80_nfft_128_overlap_10.pth'\n",
    "\n",
    "\n",
    "outputPath = '/data/liyuy/PROJECTS/DEREVERB3/LSTM/exp5/output/output_de_all/test1_wlen_80_nfft_128_overlap_10/'\n",
    "model.load_state_dict(torch.load(bst_model_fpath))\n",
    "\n",
    "\n",
    "model.eval()\n",
    "#new_count = 1\n",
    "index = 1\n",
    "Fs = 8e3\n",
    "loss = 0.0\n",
    "t60s = [0.3,0.6,0.9]\n",
    "t60_i = 0   \n",
    "i_loc = 1\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    for mag1,de_gtruth in test_dl:\n",
    "            #print(mag.shape)\n",
    "        mag1 = Variable(mag1.cuda())  # [N, 1, H, W]\n",
    "        \n",
    "        de_gtruth = Variable(de_gtruth.cuda())\n",
    "        \n",
    "            # [N, H, W] with class indices (0, 1)\n",
    "        output1 = model(mag1)# [N, 2, H, W]\n",
    "        \n",
    "        pLoss = criterion(output1,de_gtruth)\n",
    "        \n",
    "        loss += pLoss.cpu().item() * param.ts\n",
    "        avgLoss = loss/len(test_dl.dataset)\n",
    "        \n",
    " \n",
    "        \n",
    "        if index != 1 and (index - 1) % 3 == 0:\n",
    "            t60_i = 0\n",
    "            \n",
    "        de_com = output1[0].cpu().data.numpy()\n",
    "        de_com = np.squeeze(de_com)\n",
    "            \n",
    "        de_real = de_com[0]\n",
    "        de_real = np.expand_dims(de_real,axis=1)\n",
    "   \n",
    "        de_imag = de_com[0]\n",
    "        de_imag = np.expand_dims(de_imag,axis=1)\n",
    "            \n",
    "            \n",
    "        fft_de = de_real + 1j * de_imag\n",
    "            \n",
    "        com_de = fft_de[1:512]\n",
    "            #print(com_de.shape)\n",
    "            #flip and take the complex conjugate part, and combine them together\n",
    "        com_de = np.conj(np.flip(com_de))\n",
    "        new_fft_de = np.concatenate((fft_de[0:512],fft_de[512],com_de),axis=0)\n",
    "            \n",
    "        de = np.abs(np.fft.ifft(new_fft_de))\n",
    "            \n",
    "        t60 = t60s[t60_i]\n",
    "        outPath = outputPath +'te_de_'+ \"{0:0=4d}\".format(index) + '_t60' + '%f' % t60 + '_loc' + '%d' % (i_loc) +'recons.mat'\n",
    "        savemat(outPath,{'de':de})\n",
    "            \n",
    "        index += 1\n",
    "        i_loc += 1\n",
    "        t60_i += 1\n",
    "    print('Test Loss:{:>.9f}'.format(avgLoss))    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
